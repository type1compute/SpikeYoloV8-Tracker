# Traffic_Monitoring SpikeYOLO Configuration File
# Streamlined version with only actively used configurations

# =============================================================================
# DATA PATHS
# =============================================================================
data:
  # Root directory containing HDF5 files
  data_root: "/home/ubuntu/eTraM/eTraM/static/data"
  
  # Directory containing annotation files
  # Set to null to load annotations from the same directory as the HDF5 files (recommended).
  # Set to a path if annotations are in a separate directory structure.
  # NOTE: This value can be overridden by environment-specific paths in the 'environments' section.
  annotation_dir: null
  
  # Training data subdirectories
  train_folders:
    - "train_h5_1"
    - "train_h5_2" 
    - "train_h5_3"
    - "train_h5_4"
    - "train_h5_5"
    - "train_h5_6"
  
  # Validation data subdirectories
  val_folders:
    - "val_h5_1"
    - "val_h5_2"
  
  # Test data subdirectories
  test_folders:
    - "test_h5_1"
    - "test_h5_2"

# =============================================================================
# MODEL PATHS
# =============================================================================
model:
  # Directory to save model checkpoints
  checkpoint_dir: "/home/ubuntu/eTraM/eTraM/static/checkpoints/New_Run_1"
  
  # Path to trained model checkpoint
  checkpoint_path: "final_comprehensive_model.pth"
  
  # Path to best model checkpoint
  best_model_path: "best_model.pth"
  
  # Directory to save evaluation results
  results_dir: "/home/ubuntu/eTraM/eTraM/static/checkpoints/New_Run_1"
  
  # Directory to save logs
  logs_dir: "/home/ubuntu/eTraM/eTraM/static/checkpoints/New_Run_1"
  
  # Log file name (if empty, uses timestamp-based naming)
  log_file_name: "training.log"

# =============================================================================
# MODEL ARCHITECTURE
# =============================================================================
architecture:
  # Number of object classes (automatically set from classes list if not specified)
  # If not set, will be determined from the length of the classes list in config
  num_classes: null  # null = auto-detect from classes list

  # Time window in microseconds
  time_window_us: 100000  # 100ms

  # Number of time steps for temporal processing
  time_steps: 4
  
  # Tracking feature dimension
  track_feature_dim: 128

# =============================================================================
# TRAINING PARAMETERS
# =============================================================================
training:
  # Number of training epochs (updated from hyperparameter search)
  epochs: 500
  
  # Batch size (reduced to avoid 32-bit index math errors in model forward pass)
  # The model flattens [T, B, C, H, W] to [T*B, C, H, W] for convolution operations
  # With T=8, batch_size=10 gives T*B=80, which can still exceed 32-bit limits with 720×1280 spatial dims
  # batch_size=4 with T=8 gives T*B=32, which is safe for 720×1280 spatial dimensions
  # Use gradient_accumulation_steps to maintain effective batch size
  batch_size: 4  # Reduced to avoid 32-bit index math errors in convolution operations
  
  # Mixed Precision Training (Automatic Mixed Precision for faster training on H100)
  # DISABLED: SpikeYOLO operations are incompatible with FP16 (causes NaN even after FP32 training)
  # Focus on other optimizations: batch size, data loading, gradient accumulation
  use_amp: false
  
  # Gradient checkpointing trades ~10-15% compute for ~35-40% lower activation memory.
  # Enable when running into GPU memory exhaustion (recommended for 720×1280 inputs).
  use_gradient_checkpointing: true
  
  # Quantization-Aware Training (QAT) - DISABLED (slows training, only helps inference)
  use_quantization: false  # Disabled: QAT slows training by 5-15%
  
  # Direct FP16 Training - DISABLED (causes NaN with SpikeYOLO)
  # NOTE: Both AMP and direct FP16 (model.half()) cause NaN with SpikeYOLO operations
  # SpikeYOLO operations are incompatible with FP16 precision
  use_fp16: false  # Disabled: Causes NaN with SpikeYOLO
  
  # Learning rate (from best hyperparameters, works with proper initialization)
  learning_rate: 0.001  # Balanced LR with proper weight init
  
  # Minimum learning rate (prevents decay to zero)
  # Set to 5% of base LR
  min_learning_rate: 0.00005  # 5% of base LR (0.001 * 0.05)
  
  # Warmup epochs for gradual learning rate increase
  warmup_epochs: 3
  
  # Optimizer (from best hyperparameters: Trial 6 - AdamW)
  optimizer: "adamw"
  
  # Momentum for SGD (only used when optimizer is 'sgd')
  momentum: 0.9
  
  # Learning rate scheduler (from best hyperparameters: Trial 6 - cosine)
  lr_scheduler: "cosine"
  
  # Maximum learning rate for cyclic scheduler (only used when lr_scheduler is 'cyclic')
  max_learning_rate: 0.002
  
  # Learning rate decay steps (for step scheduler only - ignored for cosine scheduler)
  lr_decay_steps: 2
  
  # Learning rate decay factor (for step scheduler only - ignored for cosine scheduler)
  lr_decay: 0.5
  
  # Weight decay (from best hyperparameters: Trial 6)
  weight_decay: 0.00001509  # 1.509e-05
  
  # Gradient accumulation steps (accumulate gradients over N batches before optimizer step)
  # This simulates a larger batch size: effective_batch_size = batch_size * gradient_accumulation_steps
  # With batch_size=4 and accumulation=5: 4 * 5 = 20 effective batch size (similar to original)
  gradient_accumulation_steps: 5  # Increased to maintain effective batch size with reduced batch_size=4
  
  # Checkpoint frequency (save checkpoint every N epochs)
  checkpoint_frequency: 5
  
  # Validation frequency (validate every N epochs)
  validation_frequency: 5

# =============================================================================
# MODEL PRUNING
# =============================================================================
pruning:
  # Enable/disable pruning
  enabled: false
  
  # Pruning type: 'unstructured' (individual weights) or 'structured' (channels/filters)
  type: "unstructured"
  
  # Initial pruning amount (0.0 to 1.0)
  amount: 0.1
  
  # Maximum sparsity for iterative pruning (0.0 to 1.0)
  max_sparsity: 0.5
  
  # Pruning schedule: 'linear', 'cosine', or 'step'
  schedule: "linear"
  
  # Frequency of pruning application (every N epochs)
  frequency: 1

# =============================================================================
# YOLO LOSS CONFIGURATION
# =============================================================================
yolo_loss:
  # Box regression loss weight - TARGET: 50-60% of total loss
  # Box loss (1-IoU) typically ranges 0.3-0.6 early, 0.1-0.3 later
  # Loss component weights (corrected for proper DFL decoding)
  # Previous weights were from hyperparameter search with broken DFL code
  # These are standard YOLO-based weights adjusted for proper DFL implementation
  box_loss_weight: 7.5         # Bounding box regression loss (standard YOLO value)
  cls_loss_weight: 10.0        # Classification loss (higher to compensate for small magnitude)
  track_loss_weight: 1.0       # Tracking feature loss (learns discriminative embeddings for re-identification)
  
  # Multi-scale loss weights for Feature Pyramid Network (P5, P4, P3)
  # P5 (coarse, 23x40): Best for large objects (vehicles far away)
  # P4 (medium): Best for medium objects (nearby vehicles, large pedestrians)
  # P3 (fine): Best for small objects (pedestrians, micro-mobility)
  # Weights should sum to 1.0. Favoring P3 helps with small object detection (pedestrians)
  #scale_weights: [0.30, 0.35, 0.35]  # [P5, P4, P3] - Balanced with emphasis on P4/P3 for better pedestrian detection
  
  # IoU threshold for matching predictions to targets
  iou_threshold: 0.4  # Final target IoU threshold (balanced matches)
  
  # Box loss type: 'iou', 'giou', 'diou', 'ciou'
  # - IoU: Basic IoU loss (1 - IoU) - no gradients when boxes don't overlap
  # - GIoU: Generalized IoU - provides gradients even when boxes don't overlap
  # - DIoU: Distance IoU - considers center distance and box size
  # - CIoU: Complete IoU - considers IoU, center distance, and aspect ratio (best performance)
  box_loss_type: ciou  # Use CIoU for better localization, especially for non-overlapping boxes
  
  # Adaptive IoU threshold: start lower and increase as training progresses
  # This helps early training by allowing easier matches, then gets stricter
  use_adaptive_iou: true
  adaptive_iou_start: 0.15  # Low threshold at start to allow matches in early training
  adaptive_iou_epochs: 20   # Gradually increase from 0.15 to 0.7 over first 20 epochs
  
  # Use Focal Loss for classification (helps with hard examples)
  use_focal_loss: true
  
  # Focal Loss alpha parameter (weighting factor)
  focal_alpha: 0.25
  
  # Focal Loss gamma parameter (focusing parameter, higher = more focus on hard examples)
  focal_gamma: 2.0
  
  # Label smoothing for regularization (prevents overconfidence)
  label_smoothing: 0.1
  
  # Class weights for handling imbalanced data
  # Manual class weights: [Pedestrian, Vehicle, Micromobility]
  # Micromobility (class 2) is rarest, so give it 3x higher weight
  class_weights: [1.0, 1.0, 3.0]
  # When enabled, automatically calculates class weights from training data
  # to give more weight to rare classes and less weight to common classes
  use_class_weights: false  # Disabled - using manual weights above
  class_weight_calculation_samples: 5000  # Number of samples to use for weight calculation

# =============================================================================
# DATA PROCESSING
# =============================================================================
data_processing:
  # Image dimensions for coordinate normalization (default: event camera resolution)
  image_width: 1280.0
  image_height: 720.0
  
  # Data loading optimizations
  prefetch_factor: 4  # Prefetch batches ahead
  persistent_workers: true  # Keep workers alive between epochs for better performance
  pin_memory: true  # Faster GPU transfer with dedicated GPU
  
  # Sample configuration
  # NOTE: max_events_per_sample is now used only as a fallback/estimate
  # The code now uses time-based windows and can handle unlimited events per window (3-4M+)
  # Events are processed in chunks to avoid 32-bit index math errors
  max_events_per_sample: 10000000  # Used as fallback estimate only - actual windows use time-based limits
  max_samples_per_file: 100     # Maximum samples per HDF5 file (can lead to class imbalance when used alone)
  
  # DataLoader workers (increased for better I/O parallelization with ~60 batches)
  num_workers: 12  # Increased for better HDF5 I/O parallelization and GPU utilization
  
  # Sample caching to speed up repeated accesses (stores preprocessed samples in memory)
  cache_samples: true  # Caching on System memory
  preload_all_samples: true  # PRE-LOAD ALL SAMPLES INTO RAM during init
  debug_sample_loading: false  # Set true to log per-sample streaming info (adds overhead)
  
  # Class balancing configuration (when use_class_balanced_sampling=true)
  # Annotation-based limiting: Directly control class balance by limiting annotations per class
  max_annotations_per_class: 200  # Balanced amount for efficient training with good diversity
                                   # When set with use_class_balanced_sampling=true, directly controls class balance
                                   # null = balance to rarest class's count
  
  # Validation class balancing configuration
  # Validation uses the same annotation-based approach as training
  max_annotations_per_class_validation: null  # Maximum annotations per class for validation (null = use ratio of training)
  validation_annotation_ratio: 0.2            # Percentage of training max_annotations_per_class to use for validation (0.0-1.0)
  validation_min_annotations_per_class: 100   # Minimum annotations per class for validation
  
  # Targeted training: Only sample time windows that contain annotations
  targeted_training: true  # When enabled, only use samples with ground truth annotations
  
  # Class-balanced sampling: Ensure balanced representation across classes AND file diversity
  use_class_balanced_sampling: true  # When enabled, samples are selected to balance classes AND spread across files
  min_samples_per_class: 1  # Minimum samples per class to ensure all classes are represented
  
  # File diversity: When class-balanced sampling is enabled, ensures samples are spread across different files
  # This ensures good representation of different conditions (night/day, weather, location, etc.)
  # The selection prioritizes: 70% class balance, 30% file diversity
  # This means the model learns from diverse conditions while maintaining class balance
  
  # Annotation directory behavior:
  # - If data.annotation_dir is null (default), annotations are loaded from the same directory as the HDF5 files
  # - If data.annotation_dir is set to a path, annotations are loaded from that directory structure
  # - Environment-specific values in 'environments' section can override the base value
  # - The number of classes is automatically determined from the classes list in config

# =============================================================================
# EVALUATION PARAMETERS
# =============================================================================
evaluation:
  # IoU threshold for positive/negative classification
  iou_threshold: 0.4
  
  # Confidence threshold for detections
  confidence_threshold: 0.2  # Lowered to 0.2 to capture more predictions (especially for rare classes)
  
  # Ratio of training max_annotations_per_class to use for evaluation
  # Evaluation will use: training_max_annotations_per_class * evaluation_annotation_ratio
  evaluation_annotation_ratio: 0.2  # 20% of training max_annotations_per_class

# =============================================================================
# LOGGING AND MONITORING
# =============================================================================
logging:
  # Log level (DEBUG, INFO, WARNING, ERROR)
  level: "INFO"
  
  # Log format
  format: "%(asctime)s - %(levelname)s - %(message)s"
  
  # Print every N batches (reduced for better performance)
  print_every: 10

# =============================================================================
# DEVICE CONFIGURATION
# =============================================================================
device:
  # Force CPU usage (set to true to disable GPU)
  force_cpu: false

# =============================================================================
# CLASS NAMES
# =============================================================================
# Define your classes here. The number of classes is automatically determined from this list.
# architecture.num_classes will be automatically set to len(classes) if not explicitly set.
# Example for 3 classes:
# classes:
#   - "Pedestrian"
#   - "Vehicle"
#   - "Micro-mobility"
#
# Example for 8 classes:
classes:
  - "Pedestrian"
  - "Vehicle"
  - "Micro-mobility"

# =============================================================================
# PATHS FOR DIFFERENT ENVIRONMENTS
# =============================================================================
# Environment-specific paths that override the base values in 'data' and 'model' sections.
# The active environment is determined by 'current_environment' setting below.
# These paths automatically override:
#   - data.data_root -> environments.{env}.data_root
#   - data.annotation_dir -> environments.{env}.annotation_dir
#   - model.checkpoint_dir -> environments.{env}.checkpoint_dir
#   - model.results_dir -> environments.{env}.results_dir
#   - model.logs_dir -> environments.{env}.logs_dir
environments:
  # Local development environment
  local:
    data_root: "/Volumes/Extended/DevDependency/Type1Compute/MVP-Demo/Traffic_Monitoring/data"
    # Set to null to load annotations from same directory as HDF5 files
    # Set to a path if annotations are in a separate directory
    annotation_dir: null
    checkpoint_dir: "./checkpoints"
    results_dir: "./results"
    logs_dir: "./logs"
  
  # VM/Server environment
  vm:
    data_root: "/home/ubuntu/eTraM/eTraM/static/data"
    # Set to null to load annotations from same directory as HDF5 files
    # Set to a path if annotations are in a separate directory
    annotation_dir: null
    checkpoint_dir: "/home/ubuntu/eTraM/eTraM/static/checkpoints/New_Run_1"
    results_dir: "/home/ubuntu/eTraM/eTraM/static/checkpoints/New_Run_1"
    logs_dir: "/home/ubuntu/eTraM/eTraM/static/checkpoints/New_Run_1"
  
  # Docker environment
  docker:
    data_root: "/app/data"
    # Set to null to load annotations from same directory as HDF5 files
    # Set to a path if annotations are in a separate directory
    annotation_dir: null
    checkpoint_dir: "/app/checkpoints"
    results_dir: "/app/results"
    logs_dir: "/app/logs"

# =============================================================================
# CURRENT ENVIRONMENT
# =============================================================================
# Set this to 'local', 'vm', or 'docker' to use the corresponding paths
current_environment: "vm"
